# an automated penetration testing parser empowered by GPT
from pentestgpt.config.chatgpt_config import ChatGPTConfig
from rich.spinner import Spinner
from pentestgpt.utils.chatgpt import ChatGPT
from pentestgpt.utils.APIs.module_import import dynamic_import
from rich.console import Console
from pentestgpt.prompts.prompt_class import PentestGPTPrompt
from pentestgpt.utils.prompt_select import prompt_select, prompt_ask
from prompt_toolkit.formatted_text import HTML
from prompt_toolkit.shortcuts import confirm
from colorama import Fore
from operator import itemgetter
from rag import Rag_module
from repitition_identifier import RepititionIdentifier_module
from Tools_attach import CyberTools
from datetime import datetime
from pentestgpt.utils.task_handler import (
    main_task_entry,
    mainTaskCompleter,
    local_task_entry,
    localTaskCompleter,
)
from pentestgpt.utils.web_parser import google_search

import loguru
import time, os, textwrap, json, sys, traceback, shutil
import json
import spacy
import re
import csv

PTT_file_path = "./resources/PTT.txt"
database_path = './../Data_Collection/Nmap/file_wise/'
datapath = "./resources/knowledgebase/"
vectorPath = './resources/vectorbase/'
repitition_vector_path = './resources/repitition_vecbase/'

if os.path.exists(repitition_vector_path):
    shutil.rmtree(repitition_vector_path)

if not os.path.exists(repitition_vector_path):
    os.makedirs(repitition_vector_path)



cyber_tools = CyberTools()
#nlp = spacy.load("en_core_web_sm")
keyword_file = open('./pentestgpt/utils/keywords.txt', 'r')
keywords = keyword_file.readlines()
for i in range(len(keywords)):
    keywords[i] = keywords[i][:-1]

def find_keywords(text, keywords):

    text = text.lower()
    keywords = [keyword.lower() for keyword in keywords]
   
    doc = nlp(text)
    tokens = [token.text for token in doc]
    keyword_counts = {keyword: 0 for keyword in keywords}
    
    # Iterate through the keywords
    for keyword in keywords:
        keyword_tokens = keyword.split()
    
        for i in range(len(tokens) - len(keyword_tokens) + 1):
            if tokens[i:i+len(keyword_tokens)] == keyword_tokens:
                keyword_counts[keyword] += 1
    return keyword_counts

def select_file(database_path, keywords):
    doc_list = os.listdir(database_path)
    count_list = [0]*len(doc_list)

    for ind, doc_name in enumerate(doc_list):
        doc_name = doc_name.replace('_',' ')[:-4]
        keyword_counts = find_keywords(doc_name, keywords)
        count_list[ind] = sum(list(keyword_counts.values()))
    
    return doc_list[count_list.index(max(count_list))]

def select_commands(database_path, keywords):
    doc_list = os.listdir(database_path)
    commands = []

    for i in doc_list:
        file = open(database_path + i, 'r')
        com_text = file.read()
        commands += list(com_text.split('\n\n'))

    count_list = [0]*len(commands)

    for ind, command in enumerate(commands):
        keyword_counts = find_keywords(command, keywords)
        count_list[ind] = sum(list(keyword_counts.values()))

    res = [list(x) for x in zip(*sorted(zip(count_list, commands),
                                         key = itemgetter(0)))]
    sorted_commands = res[1]
    resultant_text = ''

    for i in range(-1,-5,-1):
        resultant_text += sorted_commands[i]
        resultant_text += '    \n\n'

    return resultant_text

def select_tool(text):
    tools = ["nmap", "metasploit", "netcat", "nikto", "gobuster", "sqlmap",
             "smbclient", "dnsrecon", "sslscan", "john_the_ripper"]

    tool_count = {}
    lower_text = text.lower()
    for tool in tools:
        count = lower_text.count(tool.lower())
        if count > 0:
            tool_count[tool] = count

    if tool_count:
        max_tool = max(tool_count, key=tool_count.get)
        return max_tool
    else:
        return None

def write_PTT(tree):
    # Serializing json
    json_object = json.dumps(tree, indent=4)

    with open(PTT_file_path, "w") as outfile:
        outfile.write(tree)

def read_PTT():
    with open (PTT_file_path,"r") as PTT_file:
        #PTT = json.load(PTT_file)
        PTT = PTT_file.read()
        return PTT


logger = loguru.logger


def prompt_continuation(width, line_number, wrap_count):
    """
    The continuation: display line numbers and '->' before soft wraps.
    Notice that we can return any kind of formatted text from here.
    The prompt continuation doesn't have to be the same width as the prompt
    which is displayed before the first line, but in this example we choose to
    align them. The `width` input that we receive here represents the width of
    the prompt.
    """
    if wrap_count > 0:
        return " " * (width - 3) + "-> "
    text = ("- %i - " % (line_number + 1)).rjust(width)
    return HTML("<strong>%s</strong>") % text


class pentestGPT:
    postfix_options = {
        "tool": "The input content is from a security testing tool. You need to list down all the points that are interesting to you; you should summarize it as if you are reporting to a senior penetration tester for further guidance.\n",
        "user-comments": "The input content is from user comments.\n",
        "web": "The input content is from web pages. You need to summarize the readable-contents, and list down all the points that can be interesting for penetration testing.\n",
        "default": "The user did not specify the input source. You need to summarize based on the contents.\n",
    }

    options_desc = {
        "tool": " Paste the output of the security test tool used",
        "user-comments": "",
        "web": " Paste the relevant content of a web page",
        "deafult": " Write whatever you want, the tool will handle it",
    }
     #o1 ,01, gpt-4o                 gpt-4  gpt-4-turbo   gpt4all
    def __init__(
        self,
        Interactive_mode_flag,
        log_dir="logs",
        reasoning_model="gpt-4-turbo",     
        parsing_model="gpt-4-turbo",       
        generator_model="gpt-4-turbo",  
        useAPI=True,
        azure=False,
        use_langfuse_logging=False,
    ):
        self.log_dir = log_dir
        self.interactive_mode_flag = Interactive_mode_flag
        logger.add(sink=os.path.join(log_dir, "pentestGPT.log"))
        self.save_dir = "test_history"
        self.task_log = (
            {}
        )  # the information that can be saved to continue in the next session
        self.useAPI = useAPI
        self.parsing_char_window = 8000  # the chunk size for parsing in # of chars
        # TODO: link the parsing_char_window to the model used
        # load the module
        reasoning_model_object = dynamic_import(
            reasoning_model, self.log_dir, use_langfuse_logging=use_langfuse_logging
        )
        generation_model_object = dynamic_import(
            generator_model, self.log_dir, use_langfuse_logging=use_langfuse_logging
        )
        parsing_model_object = dynamic_import(
            parsing_model, self.log_dir, use_langfuse_logging=use_langfuse_logging
        )

        command_extract_model_object = dynamic_import(
            parsing_model, self.log_dir, use_langfuse_logging=use_langfuse_logging
        )

        report_generator_model_object = dynamic_import(
            parsing_model, self.log_dir, use_langfuse_logging=use_langfuse_logging
        )

        results_verifier_model_object = dynamic_import(
            parsing_model, self.log_dir, use_langfuse_logging=use_langfuse_logging
        )
        
        if useAPI is False:  # deprecated usage of cookie
            self.parsingAgent = ChatGPT(ChatGPTConfig(log_dir=self.log_dir))
            self.reasoningAgent = ChatGPT(
                ChatGPTConfig(model=reasoning_model, log_dir=self.log_dir)
            )
        else:
            self.parsingAgent = parsing_model_object
            self.generationAgent = generation_model_object
            self.reasoningAgent = reasoning_model_object
            self.commandExtractor = command_extract_model_object
            self.reportGenerator = report_generator_model_object
            self.resultsVerifier = results_verifier_model_object
        self.prompts = PentestGPTPrompt
        self.console = Console()
        self.spinner = Spinner("line", "Processing")
        self.test_generation_session_id = None
        self.test_reasoning_session_id = None
        self.input_parsing_session_id = None
        self.chat_count = 0
        self.generator_memory = []
        self.repititionIdentifier = RepititionIdentifier_module()
        self.tool_output = None
        self.extracted_commands = None
        self.verify_count = 0
        self.step_reasoning = (
            None  # the response from the reasoning session for the current step
        )

        self.withRag = False
        self.withLoop = False
        self.withVerifier = True

        self.history = {
            "user": [],
            "pentestGPT": [],
            "reasoning": [],
            "input_parsing": [],
            "generation": [],
            "exception": [],
        }  # the history of the current conversation

        # print the initialization message on the current implementation.
        self.console.print(
            "Welcome to pentestGPT, an automated penetration testing parser empowered by GPT.",
            style="bold green",
        )
        self.console.print("The settings are: ")
        self.console.print(
            f" - parsing model: {parsing_model_object.name}", style="bold green"
        )
        self.console.print(
            f" - reasoning model: {reasoning_model_object.name}", style="bold green"
        )
        self.console.print(f" - use API: {useAPI}", style="bold green")
        self.console.print(f" - log directory: {log_dir}", style="bold green")
        self.generatorAgent = None
        self.PTT = None

    def log_conversation(self, source, text):
        """
        append the conversation into the history

        Parameters:
        ----------
        source: str
            the source of the conversation
        text: str
            the content of the conversation
        """
        # append the conversation into the history
        timestamp = time.time()
        if source not in self.history.keys():
            # an exception
            source = "exception"
        self.history[source].append((timestamp, text))

    def generate_report(self,raw_text_path):
        file_path = 'resources/vulnerabilities.csv'

        headers = [
            'CVE', 'CVSS', 'Risk', 'Host', 'Protocol Port', 'Name', 'Description', 'Solution', 'Vulnerability State', 
            'IP Address', 'OS', 'URL', 'First Found', 'Last Found']

        with open(file_path, mode='w', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(headers)

        raw_text_file = open(raw_text_path, 'r')
        raw_text = raw_text_file.read()
        blocks = list(raw_text.split('=============================================================================='))

        with open(file_path, mode='a', newline='') as file:
            for i in blocks[1:]:
                result_text = list(i.split('RESULTS:'))[1]
                
                string_list = self.reportGenerator.send_message(self.prompts.report_generator_init + result_text[:7500], self.report_generator_session_id)

                writer = csv.writer(file)
                writer.writerow(list(string_list.split(',')))       

    def write_raw_text(self,text):
        if text == 'clear':
            text_file = open(os.path.join(self.log_dir, 'Ablation/Pentest_raw_outputs.txt'),'w')
            text_file.close()
        else:
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            text_file = open(os.path.join(self.log_dir, 'Ablation/Pentest_raw_outputs.txt'),'a')
            text_file.write(f"[{current_time}] {text}\n")
            text_file.close()

    def refresh_session(self):
        if self.useAPI:
            self.console.print(
                "You're using API mode, so no need to refresh the session."
            )
            self.log_conversation(
                "pentestGPT",
                "You're using API mode, so no need to refresh the session.",
            )
        else:
            self.console.print(
                "Please ensure that you put the curl command into `config/chatgpt_config_curl.txt`",
                style="bold green",
            )
            self.log_conversation(
                "pentestGPT",
                "Please ensure that you put the curl command into `config/chatgpt_config_curl.txt`",
            )
            input("Press Enter to continue...")
            self.parsingAgent.refresh()
            self.reasoningAgent.refresh()
            self.console.print(
                "Session refreshed. If you receive the same session refresh request, please refresh the ChatGPT page and paste the new curl request again.",
                style="bold green",
            )
            self.log_conversation("pentestGPT", "Session refreshed.")
            return "Session refreshed."

    @staticmethod
    def find_ipv4_address(text):
        ipv4_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
        match = re.search(ipv4_pattern, text)
        if match:
            return match.group()
        return None

    def _feed_init_prompts(self):
        # 1. User firstly provide basic information of the task
        init_description = prompt_ask(
            "Please describe the penetration testing task in one line, including the target IP, task type, etc.\n> ",
            multiline=False,
        )

        target_IP = self.find_ipv4_address(init_description)
        attacker_file = open("./resources/attacker_details.txt","a")
        attacker_file.write('<Target IP> = '+ target_IP + '\n')
        attacker_file.write("""\nWordlists path: /usr/share/wordlists/\n Wordlists available:
         rockyou.txt, fasttrack.txt, dnsmap.txt, nmap.lst

         Directory list path: /usr/share/wordlists/dirbuster/\n directory lists: directory-list-2.3-medium.txt, directory-list-lowercase-2.3-medium.txt, directory-list-2.3-small.txt, directory-list-lowercase-2.3-small.txt, directory-list-1.0.txt     
         
         Metasploit wordlists path: /usr/share/wordlists/metasploit\n Wordlists available: adobe_top100_pass.txt, cms400net_default_userpass.txt, common_roots.txt, dangerzone_a.txt, db2_default_pass.txt, 
         db2_default_userpass.txt, db2_default_user.txt, default_pass_for_services_unhash.txt, default_userpass_for_services_unhash.txt, 
         default_users_for_services_unhash.txt, http_default_pass.txt, http_default_userpass.txt, http_default_users.txt, mirai_pass.txt, 
         mirai_user_pass.txt, mirai_user.txt, namelist.txt, oracle_default_hashes.txt, oracle_default_passwords.csv, 
         oracle_default_userpass.txt, password.lst, postgres_default_pass.txt, postgres_default_userpass.txt, postgres_default_user.txt, 
         root_userpass.txt, routers_userpass.txt, snmp_default_pass.txt, tftp.txt, tomcat_mgr_default_pass.txt, tomcat_mgr_default_userpass.txt, 
         tomcat_mgr_default_users.txt, unix_passwords.txt, unix_users.txt, vnc_passwords.txt\n""")
        attacker_file.close()

        RagModule = Rag_module(datapath)
        self.generatorAgent = RagModule.rag_init(vectorPath , apiKey = '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')

        self.log_conversation("Pentesting process", init_description)
        self.write_raw_text('clear')
        self.write_raw_text('PENTESTING TASK: '+init_description + '\n\n')
        self.task_log["task description"] = init_description
        # 2. Provide the information to the reasoning session for the task initialization.
        # Note that this information is not parsed by the three-step process in reasoning.
        # It is directly used to initialize the task.

        Additional_task = '\nWhat is the command to gather information like open ports (all ports), services and their version detection. Include the -Pn argument as well.'
        prefixed_init_description = self.prompts.task_description + init_description 
        
        with self.console.status(
            "[bold green] Constructing Initial Penetration Testing Tree..."
        ) as status:
            _reasoning_response = self.reasoningAgent.send_message(
                prefixed_init_description, self.test_reasoning_session_id
            )
        
        self.write_raw_text('PROPOSED STEPS FOR THE CURRENT ITTERATION:\n'+ _reasoning_response + '\n\n')
        write_PTT(_reasoning_response)

        with self.console.status("[bold green] Generating Initial Task") as status:
            _generation_response = self.generatorAgent.invoke(init_description + Additional_task)

        summarized_content_gen = self.parsingAgent.send_message(
                self.prompts.summarized_context + _generation_response, self.input_parsing_session_id
            )

        self.generator_memory.append(summarized_content_gen)

        # self.console.print("\n\n\n", "########### Input for the reasoning module #########")
        # self.console.print("prefixed_init_description:", prefixed_init_description,"\n", "test_reasoning_session_id", self.test_reasoning_session_id)
        # self.console.print("\n\n", "########### Input for the generationAgent #########")
        # self.console.print("todo_to_command:", self.prompts.todo_to_command,"\n", "_reasoning_response:", _reasoning_response, "\n", "self.test_generation_session_id:", self.test_generation_session_id, "\n")
        # self.console.print("generator output:", _generation_response )
        # Display the initial generation result
        response = _reasoning_response + "\n" + _generation_response

        self.console.print("AutoPentester output: ", style="bold green")
        self.console.print(response)
        self.log_conversation("AutoPentester", "AutoPentester output:" + response)
        #tool = select_tool(_generation_response)
        #commands_list = cyber_tools.extract_commands(_generation_response)

        extracted_output = self.commandExtractor.send_message(
                self.prompts.command_extractor + _generation_response, self.command_extractor_session_id
            )
        
        
        print('extracted_nmap_command:', extracted_output)
        self.write_raw_text('COMMANDS:\n'+ extracted_output + '\n\n')

        tool = extracted_output.split('\n')[0]
        commands_list = list(extracted_output.split('\n')[1:])
        self.extracted_commands = commands_list

        self.tool_output = cyber_tools.triger_the_tool(tool, commands_list, self)
        print(self.tool_output)
        

    def initialize(self, previous_session_ids=None):
        # initialize the backbone sessions and test the connection to chatGPT
        # define three sessions: testGenerationSession, testReasoningSession, and InputParsingSession
        if previous_session_ids is not None and self.useAPI is False:
            self.test_generation_session_id = previous_session_ids.get(
                "test_generation", None
            )
            self.test_reasoning_session_id = previous_session_ids.get("reasoning", None)
            self.input_parsing_session_id = previous_session_ids.get("parsing", None)
            # debug the three sessions
            print(f"Previous session ids: {str(previous_session_ids)}")
            print(f"Test generation session id: {str(self.test_generation_session_id)}")
            print(f"Test reasoning session id: {str(self.test_reasoning_session_id)}")
            print(f"Input parsing session id: {str(self.input_parsing_session_id)}")
            print("-----------------")
            self.task_log = previous_session_ids.get("task_log", {})
            self.console.print(f"Task log: {str(self.task_log)}", style="bold green")
            print("You may use discussion function to remind yourself of the task.")

            ## verify that all the sessions are not None
            if (
                self.test_generation_session_id is None
                or self.test_reasoning_session_id is None
                or self.input_parsing_session_id is None
            ):
                self.console.print(
                    "[bold red] Error: the previous session ids are not valid. Loading new sessions"
                )
                self.initialize()

        else:
            with self.console.status(
                "[bold green] Initialize ChatGPT Sessions..."
            ) as status:
                try:
                    (
                        text_0,
                        self.test_generation_session_id,
                    ) = self.generationAgent.send_new_message(
                        self.prompts.generation_session_init,
                    )
                    (
                        text_1,
                        self.test_reasoning_session_id,
                    ) = self.reasoningAgent.send_new_message(
                        self.prompts.reasoning_session_init
                    )
                    (
                        text_2,
                        self.input_parsing_session_id,
                    ) = self.parsingAgent.send_new_message(
                        self.prompts.input_parsing_init
                    )
                    (
                        text_3,
                        self.command_extractor_session_id,
                    ) = self.commandExtractor.send_new_message(
                        self.prompts.command_extractor_init
                    )
                    (
                        text_4,
                        self.report_generator_session_id,
                    ) = self.reportGenerator.send_new_message(
                        self.prompts.report_generator_init
                    )
                    (
                        text_5,
                        self.results_verifier_session_id,
                    ) = self.resultsVerifier.send_new_message(
                        self.prompts.results_verifier_init
                    )

                except Exception as e:
                    logger.error(e)
            
            self.console.print("- ChatGPT Sessions Initialized.\n Parsing:" + self.input_parsing_session_id + "\n Reasoning:" + self.test_reasoning_session_id + "\n Generation: " + self.test_generation_session_id + "\n Extractor: " + self.command_extractor_session_id, style="bold green")
            self._feed_init_prompts()

    def reasoning_handler(self, text) -> str:
        # summarize the contents if necessary.
        if len(text) > self.parsing_char_window:
            text = self.input_parsing_handler(text)
        """
        # pass the information to reasoning_handler and obtain the results
        response = self.reasoningAgent.send_message(
            self.prompts.process_results + text, self.test_reasoning_session_id
        )
        # log the conversation
        """
        self.PTT = read_PTT()

        # AutoPentester Reasoning Logic
        ## 1. Given the information, update the PTT
        self.console.print("\n\n\n", "########### Input for the reasoning module #########")
        self.console.print("Stage 1 Input:", self.prompts.process_results_mine + "| " + text,"\n", "test_reasoning_session_id", self.test_reasoning_session_id)
        
        self.PTT = self.reasoningAgent.send_message( self.PTT + "\n" +
            self.prompts.process_results_mine + "results secion: <r>" + text + "</r>", self.test_reasoning_session_id
        )
        write_PTT(self.PTT)
        ## 2. Validate if the PTT is correct
        # TODO
        #self.console.print("Stage 2, Validating the PTT, is ToDo")
        ## 3. If the PTT is correct, select all the to-dos
        #self.console.print("Stage 2 Input:", self.prompts.process_results_task_selection,"\n", "test_reasoning_session_id", self.test_reasoning_session_id)
        
        _task_selection_response = self.reasoningAgent.send_message("<PTT>" + self.PTT + "</PTT> " +self.prompts.process_results_task_selection , self.test_reasoning_session_id)

        self.PTT = self.reasoningAgent.send_message( self.PTT + "\n" +
            self.prompts.new_tasks_update + "New tasks: <NT>" + text + "</NT>", self.test_reasoning_session_id
        )
        write_PTT(self.PTT)

        # get the complete output:
        response = self.PTT + _task_selection_response
        
        # self.console.print("Reasoning module final response:", style = 'bold yellow')
        # self.console.print(response)

        self.log_conversation("reasoning", response)
        return _task_selection_response 


    def reasoning_handler_interactive(self, text) -> str:
        # summarize the contents if necessary.
        if len(text) > self.parsing_char_window:
            text = self.input_parsing_handler(text)
        """
        # pass the information to reasoning_handler and obtain the results
        response = self.reasoningAgent.send_message(
            self.prompts.process_results + text, self.test_reasoning_session_id
        )
        # log the conversation
        """
        self.PTT = read_PTT()

        # AutoPentester Reasoning Logic
        ## 1. Given the information, update the PTT
        self.console.print("\n\n\n", "########### Input for the reasoning module #########")
        self.console.print("Stage 1 Input:", self.prompts.process_results_mine + "| " + text,"\n", "test_reasoning_session_id", self.test_reasoning_session_id)
        
        self.PTT = self.reasoningAgent.send_message( self.PTT + "\n" +
            self.prompts.process_results_mine + "results secion: <r>" + text + "</r>", self.test_reasoning_session_id
        )
        write_PTT(self.PTT)
        ## 2. Validate if the PTT is correct
        # TODO
        #self.console.print("Stage 2, Validating the PTT, is ToDo")
        ## 3. If the PTT is correct, select all the to-dos
        #self.console.print("Stage 2 Input:", self.prompts.process_results_task_selection,"\n", "test_reasoning_session_id", self.test_reasoning_session_id)
        
        _task_selection_response = self.reasoningAgent.send_message("<PTT>" + self.PTT + "</PTT> " +self.prompts.process_results_task_selection , self.test_reasoning_session_id)

        self.PTT = self.reasoningAgent.send_message( self.PTT + "\n" +
            self.prompts.new_tasks_update + "New tasks: <NT>" + text + "</NT>", self.test_reasoning_session_id
        )
        write_PTT(self.PTT)

        # get the complete output:
        response = self.PTT + _task_selection_response

        self.log_conversation("reasoning", response)
        return response




    def input_parsing_handler(self, text, source=None, special_script = None) -> str:
        prefix = "Please summarize the following input. "
        # do some engineering trick here. Add postfix to the input to make it more understandable by LLMs.
        if source is not None and source in self.postfix_options.keys():
            prefix += self.postfix_options[source]
        # The default token-size limit is 4096 (web UI even shorter). 1 token ~= 4 chars in English
        # Use textwrap to split inputs. Limit to 2000 token (8000 chars) for each input
        # (1) replace all the newlines with spaces
        if special_script is not None:
            prefix = special_script
        text = text.replace("\r", " ").replace("\n", " ")
        # (2) wrap the text
        wrapped_text = textwrap.fill(text, 5500)
        wrapped_inputs = wrapped_text.split("\n")
        
        summarized_content = ""
        for indx, W_input in enumerate(wrapped_inputs):
            #word_limit = f"Keep the output length less than {6800 / len(wrapped_inputs)} characters.\n"

            summarized_content += self.parsingAgent.send_message_parsing(
                prefix + W_input, self.input_parsing_session_id
            )
            if indx>10:
                break
            time.sleep(2)


        #self.console.print("\n", "Sample summarization LLM prompt:", prefix + word_limit + wrapped_input, self.input_parsing_session_id)
        #self.console.print("\n", "Summarized Output", summarized_content)
        #print()
        
        # log the conversation
        self.log_conversation("input_parsing", summarized_content)
        return summarized_content

    def test_generation_handler(self, text, support_text = ''):
        # send the contents to chatGPT test_generation_session and obtain the results
        response = self.generationAgent.send_message(
            text, self.test_generation_session_id
        )
        # log the conversation
        self.log_conversation("generation", response)
        return response

    def local_input_handler(self) -> str:
        """
        Request for user's input to handle the local task
        """
        local_task_response = ""
        self.chat_count += 1
        local_request_option = local_task_entry()
        self.log_conversation("user", local_request_option)

        if local_request_option == "help":
            print(localTaskCompleter().task_details)

        elif local_request_option == "discuss":
            ## (1) Request for user multi-line input
            self.console.print(
                "Please share your findings and questions with AutoPentester."
            )
            self.log_conversation(
                "pentestGPT",
                "Please share your findings and questions with AutoPentester. (End with <shift + right-arrow>)",
            )
            user_input = prompt_ask("Your input: ", multiline=True)
            self.log_conversation("user", user_input)
            ## (2) pass the information to the reasoning session.
            with self.console.status("[bold green] AutoPentester Thinking...") as status:
                local_task_response = self.test_generation_handler(
                    self.prompts.local_task_prefix + user_input
                )
            ## (3) print the results
            self.console.print("AutoPentester:\n", style="bold green")
            self.console.print(local_task_response + "\n", style="yellow")
            self.log_conversation("pentestGPT", local_task_response)

        elif local_request_option == "brainstorm":
            ## (1) Request for user multi-line input
            self.console.print(
                "Please share your concerns and questions with AutoPentester."
            )
            self.log_conversation(
                "pentestGPT",
                "Please share your concerns and questions with AutoPentester. End with <shift + right-arrow>)",
            )
            user_input = prompt_ask("Your input: ", multiline=True)
            self.log_conversation("user", user_input)
            ## (2) pass the information to the reasoning session.
            with self.console.status("[bold green] AutoPentester Thinking...") as status:
                local_task_response = self.test_generation_handler(
                    self.prompts.local_task_brainstorm + user_input
                )
            ## (3) print the results
            self.console.print("AutoPentester:\n", style="bold green")
            self.console.print(local_task_response + "\n", style="yellow")
            self.log_conversation("pentestGPT", local_task_response)

        elif local_request_option == "google":
            # get the users input
            self.console.print(
                "Please enter your search query. AutoPentester will summarize the info from google. (End with <shift + right-arrow>) ",
                style="bold green",
            )
            self.log_conversation(
                "pentestGPT",
                "Please enter your search query. AutoPentester will summarize the info from google.",
            )
            user_input = prompt_ask("Your input: ", multiline=False)
            self.log_conversation("user", user_input)
            with self.console.status("[bold green] AutoPentester Thinking...") as status:
                # query the question
                result: dict = google_search(user_input, 5)  # 5 results by default
                # summarize the results
                # TODO
                local_task_response = (
                    "Google search results:\n" + "still under development."
                )
            self.console.print(local_task_response + "\n", style="yellow")
            self.log_conversation("pentestGPT", local_task_response)
            return local_task_response

        elif local_request_option == "continue":
            self.console.print("Exit the local task and continue the main task.")
            self.log_conversation(
                "pentestGPT", "Exit the local task and continue the main task."
            )
            local_task_response = "continue"

        return local_task_response

    def ACI(self, generated_response):
        extracted_output = self.commandExtractor.send_message(
                self.prompts.command_extractor + generated_response, self.command_extractor_session_id
            )
        
        
        print('##### extracted_commands:', extracted_output)
        print()
        tool = list(extracted_output.split('\n'))[0]
        tool_list = tool.split(',')
        
        if len(tool_list)>1:
            tool_wise_commands = list(extracted_output[extracted_output.find('\n')+1:].split('\n<next_tool>\n'))
        else:
            tool_wise_commands = list(extracted_output.split('\n'))[1:]

        self.extracted_commands = tool_wise_commands
        
        self.tool_output = ''
        for i, tool in enumerate(tool_list):
            self.tool_output += f'{tool} output\n'
            if len(tool_list) >1:
                temp_command_list = list(tool_wise_commands[i].split('\n'))
            else:
                temp_command_list = tool_wise_commands

            print('TOOL: ', tool)
            print('COMMANDS:', temp_command_list)

            for j, com in enumerate(temp_command_list):
                if 'msf6>' in com:
                    temp_command_list[j] = com.split('msf6>')[1]
            
            tool_output = cyber_tools.triger_the_tool(tool, temp_command_list, self)
            self.tool_output += (tool_output + '\n\n')
        
        print(self.tool_output)
        return self.tool_output

    def ResultsVerifier(self, response):
        default_file = open('./resources/attacker_details.txt','r')
        default_info = 'Attack Network Information:\n' + default_file.read()
        
        updated_commands = self.resultsVerifier.send_message(
                self.prompts.results_verifier_command + '\nCommands\n' + str(self.extracted_commands) + '\nResults\n' + response + 
                '\nWhen adjusting the commands, you can use the following resources. Only output the finalized commands. Only if there a adjustment, the first line of the output should be ADJUSTMENT\n' + default_info , self.results_verifier_session_id
            )
        return updated_commands


    def input_handler(self) -> str:
        """
        Request for user's input to:
            (1) input test results,
            (2) ask for todos,
            (3) input other information (discuss),
            (4) google.
            (4) end.
        The design details are based on PentestGPT_design.md

        Return
        -----
        response: str
            The response from the chatGPT model.
        """
        self.chat_count += 1

        #request_option = main_task_entry()
        request_option = "next"
        self.log_conversation("user", request_option)

        guided_text = ''

        # always check if the session expires.
        # check if session expires
        if not self.useAPI:
            conversation_history = self.parsingAgent.get_conversation_history()
            while conversation_history is None:
                self.refresh_session()
                conversation_history = self.parsingAgent.get_conversation_history()

        if request_option == "help":
            print(mainTaskCompleter().task_details)

        if request_option == "next":
            
            user_input = self.tool_output

            # options[int(source)] = 'tool'
            self.log_conversation(
                "user", f"Source: {'tool'}" + "\n" + user_input
            )
            print("\n\n########## AT THE PARSING HANDLER ###########\n\n")
            print("Parsing input length:", len(user_input))
            with self.console.status("[bold green] AutoPentester Thinking...") as status:
                parsed_input = self.input_parsing_handler(
                    user_input, source='tool'
                )
                self.write_raw_text('RAW TOOL OUTPUT:\n' + user_input + '\n\n')
                self.write_raw_text('RESULTS:\n' + parsed_input + '\n\n')
                self.write_raw_text('=======================================================================================\n\n')
                
                if self.withVerifier:
                    verify = self.ResultsVerifier(parsed_input)
                    print('\n\n\n Verfiy Output:',verify,'\n\n')

                    if verify[:10].lower() == "adjustment" and self.verify_count< 2:
                        self.verify_count += 1
                        self.write_raw_text('VERIFIED COMMANDS:\n'+ verify + '\n\n')
                        return self.ACI(verify)
                    
                    else:
                        self.verify_count = 0


                ## (2) pass the summarized information to the reasoning session.
                reasoning_response = self.reasoning_handler(parsed_input)
                self.step_reasoning_response = reasoning_response

            ## (3) print the results
            self.console.print(
                "Based on the analysis, the following tasks are recommended:",
                style="bold green",
            )
            self.console.print("##### Reasoning response\n" + reasoning_response + "\n")
            self.log_conversation(
                "pentestGPT",
                "Based on the analysis, the following tasks are recommended:"
                + reasoning_response,
            )

            generator_input = list(reasoning_response.split('<Next_task>'))[1]

            self.write_raw_text('PROPOSED STEPS FOR THE CURRENT ITTERATION:\n'+ generator_input+ '\n\n')

            repitition = False
            if self.withLoop:
                summarized_content_gen = self.parsingAgent.send_message_parsing(
                    self.prompts.summarized_context + generator_input, self.input_parsing_session_id
                )
                print('\n\n\nSummarized Content:\n\n', summarized_content_gen + '\n\n------------------------\n')
                repitition, highest_match = self.repititionIdentifier.detect(summarized_content_gen, self.generator_memory, repitition_vector_path)

                print('Repitition Found:', repitition)
                self.generator_memory.append(summarized_content_gen)
            
            if repitition:
                human_input = self.repititionIdentifier.human_react(self.PTT, summarized_content_gen, highest_match, self.console)
                
                if human_input == 'interactive':
                    self.write_raw_text('\n\nRepitition identified. Switching to the interactive mode.\n\n')
                    self.interactive_mode_flag = True
                    return generator_input

                elif human_input == 'exit':
                    response = False
                    self.end_program = True
                    self.console.print("Thank you for using AutoPentester!", style="bold green")
                    self.log_conversation("pentestLLM", "Thank you for using AutoPentester!")
                
                elif human_input != 'continue':
                    reasoning_response = self.reasoning_handler(human_input)
                    self.step_reasoning_response = reasoning_response
                    self.console.print(
                        "Based on the analysis, the following tasks are recommended:",
                        style="bold green",
                    )
                    self.console.print("##### Reasoning response\n" + reasoning_response + "\n")
                    self.log_conversation(
                        "pentestGPT",
                        "Based on the analysis, the following tasks are recommended:"
                        + reasoning_response,
                    )
                    generator_input = list(reasoning_response.split('<Next_task>'))[1]

            if self.withRag:
                generated_response = self.generatorAgent.invoke( self.prompts.rag_generation_command + generator_input)
                #generated_response = self.test_generation_handler( generator_input, support_text=guided_text)
            else:
                generated_response = self.generationAgent.send_message(self.prompts.command_generation + generator_input, self.test_generation_session_id)

            self.console.print(
                "\n\nThe Following steps are identified. Please run the given commands in the relevant tool:",
                style="bold yellow",
            )
            self.console.print(generated_response + "\n", style="green")
            response = reasoning_response

            self.write_raw_text('COMMANDS:\n'+ generated_response + '\n\n')

            #tool = select_tool(generated_response)
            #commands_list = cyber_tools.extract_commands(generated_response)
            response = self.ACI(generated_response)

        else:
            self.console.print("Please key in the correct options.", style="bold red")
            self.log_conversation("pentestGPT", "Please key in the correct options.")
            response = "Please key in the correct options."
        return response




    def input_handler_interactive(self) -> str:
        """
        Request for user's input to:
            (1) input test results,
            (2) ask for todos,
            (3) input other information (discuss),
            (4) google.
            (4) end.
        The design details are based on PentestGPT_design.md

        Return
        -----
        response: str
            The response from the chatGPT model.
        """
        self.chat_count += 1

        request_option = main_task_entry()
        self.log_conversation("user", request_option)
        # always check if the session expires.
        # check if session expires
        if not self.useAPI:
            conversation_history = self.parsingAgent.get_conversation_history()
            while conversation_history is None:
                self.refresh_session()
                conversation_history = self.parsingAgent.get_conversation_history()

        if request_option == "help":
            print(mainTaskCompleter().task_details)

        if request_option == "next":
            ## (1) pass the information to input_parsing session.
            ## Give an option list for user to choose from
            options = list(self.postfix_options.keys())
            opt_desc = list(self.options_desc.values())

            value_list = [
                (
                    i,
                    HTML(
                        f'<style fg="cyan">{options[i]}</style><style fg="LightSeaGreen">{opt_desc[i]}</style>'
                    ),
                )
                for i in range(len(options))
            ]
            source = prompt_select(
                title="Please choose the source of the information.", values=value_list
            )
            self.console.print(
                "Your input: (End with <shift + right-arrow>)", style="bold green"
            )
            user_input = prompt_ask("> ", multiline=True)
            self.log_conversation(
                "user", f"Source: {options[int(source)]}" + "\n" + user_input
            )
            with self.console.status("[bold green] AutoPentester Thinking...") as status:
                parsed_input = self.input_parsing_handler(
                    user_input, source=options[int(source)]
                )
                self.write_raw_text('RAW TOOL OUTPUT:\n' + user_input + '\n\n')
                self.write_raw_text('RESULTS:\n' + parsed_input + '\n\n')
                self.write_raw_text('=======================================================================================\n\n')

                ## (2) pass the summarized information to the reasoning session.
                reasoning_response = self.reasoning_handler_interactive(parsed_input)
                self.step_reasoning_response = reasoning_response

            ## (3) print the results
            self.console.print(
                "Based on the analysis, the following tasks are recommended:",
                style="bold green",
            )
            self.console.print(reasoning_response + "\n")
            self.log_conversation(
                "pentestGPT",
                "Based on the analysis, the following tasks are recommended:"
                + reasoning_response,
            )
            self.write_raw_text('\nPROPOSED STEPS FOR THE CURRENT ITTERATION:\n'+ reasoning_response+ '\n\n')
            response = reasoning_response

            generator_input = list(reasoning_response.split('<Next_task>'))[1]

            generated_response = self.generatorAgent.invoke( self.prompts.rag_generation_command + generator_input)
            #generated_response = self.test_generation_handler( generator_input, support_text=guided_text)
            
            self.console.print(
                "\n\nThe Following steps are identified. Please run the given commands in the relevant tool:",
                style="bold yellow",
            )
            self.console.print(generated_response + "\n", style="green")

        elif request_option == "more":
            self.log_conversation("user", "more")
            ## (1) check if reasoning session is initialized
            if not hasattr(self, "step_reasoning_response"):
                self.console.print(
                    "You have not initialized the task yet. Please perform the basic testing following `next` option.",
                    style="bold red",
                )
                response = "You have not initialized the task yet. Please perform the basic testing following `next` option."
                self.log_conversation("pentestGPT", response)
                return response
            ## (2) start local task generation.
            ### (2.1) ask the reasoning session to analyze the current situation, and explain the task
            self.console.print(
                "AutoPentester will generate more test details, and enter the sub-task generation mode. (Pressing Enter to continue)",
                style="bold green",
            )
            self.log_conversation(
                "pentestGPT",
                "AutoPentester will generate more test details, and enter the sub-task generation mode.",
            )
            input()

            ### (2.2) pass the sub-tasks to the test generation session
            with self.console.status("[bold green] AutoPentester Thinking...") as status:
                generation_response = self.test_generation_handler(
                    self.step_reasoning_response
                )
                _local_init_response = self.test_generation_handler(
                    self.prompts.local_task_init
                )

            self.console.print(
                "Below are the further details.",
                style="bold green",
            )
            self.console.print(generation_response + "\n")
            response = generation_response

            self.write_raw_text(response + '\n\n')
            self.log_conversation("pentestGPT", response)

            ### (2.3) local task handler
            while True:
                local_task_response = self.local_input_handler()
                if local_task_response == "continue":
                    # break the local task handler
                    break

        elif request_option == "todo":
            ## log that user is asking for todo list
            self.log_conversation("user", "todo")
            ## (1) ask the reasoning session to analyze the current situation, and list the top sub-tasks
            with self.console.status("[bold green] AutoPentester Thinking...") as status:
                reasoning_response = self.reasoning_handler(self.prompts.ask_todo)
                ## (2) pass the sub-tasks to the test_generation session.
                message = self.prompts.todo_to_command + "\n" + reasoning_response
                generation_response = self.test_generation_handler(message)
                ## (3) print the results
            self.console.print(
                "Based on the analysis, the following tasks are recommended:",
                style="bold green",
            )
            self.console.print(reasoning_response + "\n")
            self.console.print(
                "You can follow the instructions below to complete the tasks.",
                style="bold green",
            )
            self.console.print(generation_response + "\n")
            response = reasoning_response
            self.log_conversation(
                "pentestGPT",
                (
                    (
                        (
                            (
                                "Based on the analysis, the following tasks are recommended:"
                                + response
                            )
                            + "\n"
                        )
                        + "You can follow the instructions below to complete the tasks."
                    )
                    + generation_response
                ),
            )
        elif request_option == "discuss":
            ## (1) Request for user multi-line input
            self.console.print(
                "Please share your thoughts/questions with AutoPentester. (End with <shift + right-arrow>) "
            )
            self.log_conversation(
                "pentestGPT", "Please share your thoughts/questions with AutoPentester."
            )
            user_input = prompt_ask("Your input: ", multiline=True)
            self.log_conversation("user", user_input)
            ## (2) pass the information to the reasoning session.
            with self.console.status("[bold green] AutoPentester Thinking...") as status:
                response = self.reasoning_handler(self.prompts.discussion + user_input)
            ## (3) print the results
            self.console.print("AutoPentester:\n", style="bold green")
            self.console.print(response + "\n", style="yellow")
            self.log_conversation("pentestGPT", response)

        elif request_option == "google":
            # get the users input
            self.console.print(
                "Please enter your search query. AutoPentester will summarize the info from google. (End with <shift + right-arrow>) ",
                style="bold green",
            )
            self.log_conversation(
                "pentestGPT",
                "Please enter your search query. AutoPentester will summarize the info from google.",
            )
            user_input = prompt_ask("Your input: ", multiline=False)
            self.log_conversation("user", user_input)
            with self.console.status("[bold green] AutoPentester Thinking...") as status:
                # query the question
                result: dict = google_search(user_input, 5)  # 5 results by default
                # summarize the results
                # TODO
                response = "Google search results:\n" + "still under development."
            self.console.print(response + "\n", style="yellow")
            self.log_conversation("pentestGPT", response)
            return response

        elif request_option == "quit":
            response = False
            self.console.print("Thank you for using AutoPentester!", style="bold green")
            self.log_conversation("pentestGPT", "Thank you for using AutoPentester!")

        else:
            self.console.print("Please key in the correct options.", style="bold red")
            self.log_conversation("pentestGPT", "Please key in the correct options.")
            response = "Please key in the correct options."
        return response

    

    def save_session(self):
        """
        Save the current session for next round of usage.
        The test information is saved in the directory `./test_history`
        """
        self.console.print(
            "Before you quit, you may want to save the current session.",
            style="bold green",
        )
        # 1. Require a save name from the user. If not, use the current time as the save name.
        save_name = prompt_ask(
            "Please enter the name of the current session. (Default with current timestamp)\n> ",
            multiline=False,
        )
        if save_name == "":
            save_name = str(time.time())
        # 2. Save the current session
        with open(
            os.path.join(
                os.path.realpath(os.path.dirname(__file__)),
                os.pardir,
                os.pardir,
                self.save_dir,
                save_name,
            ),
            "w",
        ) as f:
            # store the three ids and task_log
            session_ids = {
                "reasoning": self.test_reasoning_session_id,
                "test_generation": self.test_generation_session_id,
                "parsing": self.input_parsing_session_id,
                "task_log": self.task_log,
            }
            json.dump(session_ids, f)
        self.console.print(
            f"The current session is saved as {save_name}", style="bold green"
        )
        return

    def _preload_session(self) -> dict:
        """
        Preload the session from the save directory.

        Returns:
            dict: the session ids for the three sessions.
            None if no previous session is found.
        """
        if continue_from_previous := confirm(
            "Do you want to continue from previous session?"
        ):
            # load the filenames from the save directory
            filenames = os.listdir(
                os.path.join(
                    os.path.realpath(os.path.dirname(__file__)),
                    os.pardir,
                    os.pardir,
                    self.save_dir,
                )
            )
            if len(filenames) == 0:
                print("No previous session found. Please start a new session.")
                return None
            else:  # print all the files
                print("Please select the previous session by its index (integer):")
                for i, filename in enumerate(filenames):
                    print(f"{str(i)}. {filename}")
                # ask for the user input
                try:
                    previous_testing_name = filenames[
                        int(input("Please key in your option (integer): "))
                    ]
                    print(f"You selected: {previous_testing_name}")
                except ValueError as e:
                    print("You input an invalid option. Will start a new session.")
                    return None

        elif continue_from_previous is False:
            return None
        else:
            print("You input an invalid option. Will start a new session.")
            return None
        # 2. load the previous session information
        if previous_testing_name is not None:
            # try to load the file content with json
            try:
                with open(
                    os.path.join(
                        os.path.realpath(os.path.dirname(__file__)),
                        os.pardir,
                        os.pardir,
                        self.save_dir,
                        previous_testing_name,
                    ),
                    "r",
                ) as f:
                    return json.load(f)
            except Exception as e:
                print(
                    "Error when loading the previous session. The file name is not correct"
                )
                print(e)
                previous_testing_name = None
                return None

    def main(self):
        """
        The main function of pentestGPT. The design is based on PentestGPT_design.md
        """

        my_IP = str(input("Enter your IP: "))
        default_data = 'My IP is ' + my_IP + """.\n The wordlists that are used in tools are in the /usr/share/wordlists/. The content is as follows. \n   """

        attacker_file = open("./resources/attacker_details.txt","w")
        attacker_file.write('Following information should be used when generating commands for the cyber tools and shold replace target IP, uyour IP and username password wordlists paths.\n')
        attacker_file.write('<My IP> = '+ my_IP + '\n')
        attacker_file.close()

        # 0. initialize the backbone sessions and test the connection to chatGPT
        loaded_ids = self._preload_session()
        self.initialize(previous_session_ids=loaded_ids)

        self.end_program = False
        # enter the main loop.
        while not self.end_program:
            try:
                if self.interactive_mode_flag:
                    result = self.input_handler_interactive()
                else:
                    result = self.input_handler()
                self.console.print(
                    "-----------------------------------------", style="bold white"
                )
                if self.end_program:  # end the session
                    break
            except Exception as e:  # catch all general exception.
                # log the exception
                self.log_conversation("exception", str(e))
                # print the exception
                self.console.print(f"Exception: {str(e)}", style="bold red")
                # add a more detailed debugging
                exc_type, exc_obj, exc_tb = sys.exc_info()
                fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
                self.console.print(
                    "Exception details are below. You may submit an issue on github and paste the error trace",
                    style="bold green",
                )
                # self.console.print(exc_type, fname, exc_tb.tb_lineno)
                print(traceback.format_exc())
                # safely quit the session
                break
        # log the session. Save self.history into a txt file based on timestamp
        timestamp = time.time()
        log_name = f"pentestGPT_log_{str(timestamp)}.txt"
        # save it in the logs folder
        log_path = os.path.join(self.log_dir, log_name)
        with open(log_path, "w") as f:
            json.dump(self.history, f)

        self.generate_report(os.path.join(self.log_dir, 'Ablation/Pentest_raw_outputs.txt'))

        # save the sessions; continue from previous testing
        self.save_session()


if __name__ == "__main__":
    Interactive_mode_flag = False
    pentestGPT = pentestGPT(Interactive_mode_flag)
    pentestGPT.main()
