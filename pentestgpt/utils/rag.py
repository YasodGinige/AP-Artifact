from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader
from langchain import hub
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings


class Rag_module():
    def __init__(self, datapath):
        self.loader = DirectoryLoader(datapath,glob="*.pdf",loader_cls=PyPDFLoader)
        self.text_splitter  = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)
        self.dataChunks = None
        self.vectorStore = None
        self.retriever = None
        self.llm = None

    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

    def rag_invoke(self,vectorPath , apiKey = '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'):
        documents = self.loader.load()
        self.dataChunks = self.text_splitter.split_documents(documents)
        self.vectorStore = Chroma.from_documents(documents=self.dataChunks,
                                    embedding=OpenAIEmbeddings(openai_api_key=apiKey),
                                    persist_directory=vectorPath)
        
        self.vectorstore.persist()

        self.retriever = self.vectorstore.as_retriever(search_kwargs={'k':20})
        prompt = hub.pull('rlm/rag-prompt')

        #prompt.messages[0].prompt.template = "You are a Cybersecurity expert for question-answering tasks. Use the following pieces of retrieved context to answer the question. If the context doesn't contain a direct answer, combine these commands to generate the expected outcome. Use three sentences maximum and keep the answer concise.\nQuestion: {question} \nContext: {context} \nAnswer:"
        prompt.messages[0].prompt.template = "You are a Cybersecurity expert for question-answering tasks. Use the following pieces of retrieved context and your existing knowledge to answer the question. If the context doesn't contain a direct answer, combine these commands and your existing knowledge to generate the expected outcome. Use three sentences maximum and keep the answer concise.\nQuestion: {question} \nContext: {context} \nAnswer:"
        
        self.llm = ChatOpenAI(model_name="gpt-4", temperature=0.2, openai_api_key=apiKey)

        rag_chain = ({"context": retriever | format_docs, "question": RunnablePassthrough()}
                    | prompt
                    | llm
                    | StrOutputParser())

        return rag_chain